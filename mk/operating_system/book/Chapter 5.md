# 운영체제 5장 정리

CPU 스케쥴링
- CPU 스케쥴링 : 다중 프로그램 OS의 기본. CPU 이용률을 최대화하기 위해 항상 실행 중인 프로세스를 가지게 하는 것이 목표
- 최신 OS는 실질적으로 프로세스가 아닌 커널 수준 스레드를 스케쥴한다
- 작동 원리 : OS는 준비 큐에 있는 프로세스 중 하나를 선택해 실행함. 선택 절차는 CPU 스케쥴러에 의해 실행됨

선점 스케쥴링 vs 비선점 스케쥴링
- 선점 스케쥴링(preemptive) : 프로세스가 CPU에 올라가 있어도 이를 밀어내고 수행될 수 있음
- 비선점 스케쥴링(nonpreemptive) : 프로세스가 종료 혹은 대기 상태가 되어 CPU를 방출할 때 까지 CPU를 점유
- 현대 OS는 선점 스케쥴링을 사용

디스패처(Dispatcher)
- CPU 코어의 제어를 CPU 스케쥴러가 선택한 프로세스에 주는 모듈
- Context Switching, User Mode 전환, jump 작업도 포함됨.

스케쥴링 기준
- CPU 이용률 : 가능한 한 CPU를 바쁘게 유지할 것
- 처리량 : 단위 시간당 처리되는 프로세스의 개수가 최대일 것
- 총처리 시간 : 프로세스를 실행할 때 제출 시간과 완료 시간의 간격을 최소화할 것
- 대기 시간 : 프로세스가 준비 큐에서 대기하는 시간을 최소화할 것
- 응답 시간 : 하나의 요구를 제출했을 때 첫 번째 응답이 나오는 시간을 최소화할 것
- 대부분의 경우, 평균 측정 시간을 최적화하려고 한다

스케쥴링 알고리즘의 종류
- FCFS
- SJF
- Round Robin
- 우선순위(Priority)
- 다단계 큐(Multilevel Queue)
- 다단계 피드백 큐(Multilevel Feedback Queue)

스레드 스케쥴링
- 최신 OS에서 스케쥴되는 대상은 프로세스가 아니라 커널 수준의 스레드이다
- 사용자 수준 스레드는 CPU상에서 실행되기 위해 궁극적으로 연관된 커널 수준 스레드에 mapping되어야 함
- 프로세스 경쟁 범위(PCS : process contention scope) : 프로세스 내에서 사용자 스레드들 사이의 경쟁 범위. 1개의 커널 스레드를 두고 다수의 사용자 스레드가 경쟁함
- 시스템 경쟁 범위(SCS : system contention scope) : 시스템 내에서 커널 스레드들 사이의 경쟁 범위. 1개의 CPU를 두고 다수의 커널 스레드가 경쟁함
- 전형적으로 PCS는 우선순위를 따진다

다중 처리기 스케쥴링
- 다중 처리기 : 복수의 물리적 프로세스를 제공하는 시스템
- 부하 공유(load sharing) : 다중 처리 환경에서 여러 스레드가 병렬로 실행될 수 있으므로 코어끼리 부하를 공유할 수 있음
- 다중 처리기는 다음 시스템 아키텍쳐에서 사용 가능함
  1. 다중 코어 CPU
  2. 다중 스레드 코어
  3. NUMA
  4. 이기종 다중 처리

대칭 다중 처리와 비대칭 다중 처리
- 비대칭 다중 처리 : 1개의 처리기를 마스터 서버로 선정하여 모든 스케쥴링 결정, I/O 처리 및 다른 시스팀 활동을 취급하도록 시킴
- 대칭 다중 처리(SMP: symmetric multiprocessing) : 각 처리기는 스스로 스케줄링할 수 있음
- 대부분의 운영체제는 SMP를 사용함

다중 코어 프로세서
- SMP 시스템은 다수의 물리 처리기를 제공하여 다수의 프로세스가 병렬로 실행되기 함
- 현대 HW는 동일한 물리 칩 안에 복수의 프로세스 코어를 포함 -> 다중 코어 프로세서의 등장(multicore processor)
- 각 코어(CPU X)는 OS 입장에서 개별적인 논리 CPU로 보임
- 메모리 스톨(memory stall) : 프로세서가 메모리에 접근할 때 데이터가 사용 가능해질 때까지 대기하면 허송 세월 보내는 현상
- 메모리 스톨은 최신 프로세서가 메모리보다 훨씬 빠른 속도로 작동하기 때문에 발생한다.
- 메모리 스톨을 해결하기 위해 하드웨어 스레드가 등장 : 각 코어는 2개 이상의 하드웨어 스레드를 할당받음 -> 칩 다중 스레딩(chip multithreading)
- 인텔은 단일 HW 코어에 여러 HW 스레드를 할당하는 것을 하이퍼스레딩이라는 용어로 설명한다

부하 균등화
- SMP 시스템의 모든 프로세서 사이에 부하가 고르게 배분될 수 있도록 함
- push 이주 : 특정 태스크가 주기적으로 각 프로세서의 부하를 검사, 과부하 상태의 프로세서에서 쉬고있는 프로세서로 스레드를 이동시켜 부하를 분배
- pull 이주 : 쉬고 있는 프로세서가 바쁘게 일하는 프로세서를 기다리는 프로세스를 pull함

처리기 선호도
- 스레드에 의해 가장 최근에 접근된 데이터가 프로세서의 캐시를 채움
- 해당 스레드의 잇따른 접근은 캐시 히트율이 높음 (warm cache)
- 이 때 스레드가 다른 프로세서로 이동하는 순간 캐시 메모리를 날리고 새로운 데이터로 갱신해야 함
- 해당 작업이 생각보다 비용이 비싸기 때문에, SMP를 지원하는 대부분의 OS는 스레드를 다른 프로세서로 웬만하면 이동시키지 않는다 -> 프로세서 선호도 개념의 등장
- 약한 선호도 : 동일 처리기에서 프로세스를 실행하려고 노력은 하지만 보장하지는 않음
- 강한 선호도 : 프로세스는 자신이 실행될 프로세서 집합을 명시함(리눅스의 sched_setafficnity())
- 부하를 균등화하는 시도는 종종 프로세서 선호도의 이점을 상쇄해버린다 : 동일한 프로세서에서 꾸준히 실행되어야 캐시 히트율이 높은데 이를 무시하고 부하를 분배하기 때문.

이기종 다중 처리
- 모바일 시스템의 다중 코어 시스템에서 일부 코어는 동일한 명령어 집합을 실행하지만 전력 소비를 유휴 수준으로 조정하는 기능을 포함하여 클록 속도 및 전력 관리 측면에서 성능 차이가 나는 코어를 사용.
- ARM 프로세서의 경우 big, LITTLE 아키텍쳐라고 부름
- big 프로세서 : 많은 에너지를 사용 but 성능 좋음 (따라서 짧은 시간만 이용해야 함)
- little 프로세서 : 적은 에너지를 사용 but 성능 조금 떨어짐 (따라서 더 오랫동안 사용 가능)

실시간 CPU 스케줄링
- 연성 실시간 시스템 : 중요한 실시간 프로세스가 스케쥴 되는 시점에 관해 아무런 보장을 하지 않음
- 경성 실시간 시스템 : 태스크는 반드시 마감시간까지 서비스를 받아야 하며 마감시간 이후 서비스를 받으면 서비스를 전혀 받지 않은 것과 같은 결과를 낳음

지연시간
- 이벤트 지연시간 : 시스템은 이벤트가 발생하면 가능한 빨리 응답하고 그에 맞는 서비스를 수행해야 함 -> 이벤트 발생 후 서비스가 수행될때 까지 소요된 시간
- 인터럽트 지연시간 : CPU에 인터럽트가 발생한 시점부터 해당 인터럽트 처리 루틴이 수행될 때 까지 소요된 시간
- 디스패치 지연시간 : 스케줄링 디스패처가 하나의 프로세스를 블록시키고 다른 프로세스를 시작하는 데까지 소요된 시간

실시간 OS 환경에서의 스케줄링 기법
- 우선순위 기반 스케줄링
- Rate-Monotonic 스케줄링
- Earliest-Deadline-First 스케줄링
- 일정 비율의 몫 스케줄링
- POSIX 실시간 스케줄링

상용 OS의 스케줄링 예시
- Linux : 완벽한 공정 스케줄러(CFS)를 사용하여 각 작업마다 일정 비율의 CPU 처리 시간을 할당함. 비율은 각 작업과 관련된 가상 실행시간 vruntime 값을 기준으로 함.
- Windows : 선점적인 32단계 우선순위 기법을 사용하여 스레드 스케줄링 순서를 결정함



